

# Approach/ methodology and overview of research question(s)
* We worked from the ground up - letting the field emerge from the analysis rather than pre-defining the boundaries of the field
	* *Borrow as much as possible from the launch blog post and work note, eg why we’re not trying to define the boundaries of the field (ie working from the ground up) and starting with funders (ie tracing the funding cycle)*
* Our research questions were…
	* Our main research question was: What is going on in the data-related research landscape?
	* Our secondary research questions were:
		* Who is funding research in this area?
			* In the UK, who are the major funders of ‘data-related research’ - ie research about data, its value, uses and impacts?
			* How much funding do they direct toward ‘data-related research’ each year? How much in past years? How much is planned for future years?
			* What is the process for securing funding/ what are the requirements? 
		* What ‘data-related’ topics are being funded by these organisations? 
			* What is currently big in the world of data, tech, policy, governance, new uses of data, etc.? 
			* What are going to be the next big things in data over the next one, five, ten years?
	* Some of which could be answered via qualt research, some via quant, and some through a mix
* We started by speaking to funders because
	* It made sense to follow the money (funding → research → publication → impact)
	* It was more manageable
	* We spoke to 
		* Philanthropic funders
			* Wellcome
			* Sloan Foundation
			* Open Society
			* Ford Foundation
			* Lloyd’s Register Foundation
			* Nuffield Foundation
		* UK Research and Innovation (UKRI)
			* Biotechnology and Biological Sciences Research Council (BBSRC) 
			* Engineering and Physical Sciences Research Council (EPSRC)
			*   Arts and Humanities Research Council (AHRC)
			* Science and Technology Facilities Council (STFC)
			* Medical Research Council (MRC)
			* Natural Environment Research Council (NERC)
			* Innovate UK
	* Brief description of methods (but not too much - people understand interviews and thematic coding of transcripts)
		* Desk research on funders
			* Interested in understanding (a) general information about the organisation – core goals or mission, governance paradigm, and sector, (b) type of funding organisation – the functions it fulfils or services it provides, (c) main activities and projects going on.
		* Interviews with funders
			* Type of funders [research councils, philanthropic bodies, all doing research in the UK, interested in data-related topics] 
			* We asked them about
				* The role they see for themselves in the data-related research landscape
				* How they decide which topics to fund
				* How the application review process works
				* If/how they track the impact they have
				* If/how they engage with other funders as part of the funding process
* We then moved to quantitatively analyse funding, research, publication, impact
	* We first identified datasets that would enable us to answer our research questions, each of which has specific benefits and limitations
		* GtR
		* 360Giving
		* Lens Scholar (mention and thank Lens - probably also mention Lens near each table or chart)
	* Defined our parameters
		* Ten keywords chosen from Data 2020
			* For the sake of simplicity, we adopted an initial, heuristic definition of ‘data-related research’ as a cluster of ten keywords drawn from the ten ‘hot topics’ in  [Data 2020](https://theodi.org/article/data-2020/) .
				* Data ethics
				* Data sharing
				* Misinformation
				* Data infrastructure
				* Digital economy
				* Value of data
				* Data rights
				* Data literacy
				* Digital trade
				* Automated decision-making
			* Had to start somewhere in terms of what we meant by ‘data-related research’
				* With the intention of then expanding and snowballing these terms into adjacent terms, related areas etc.
			* This was the ODI’s estimation of what would be important in 2020, so this also enabled us to check our work in a sense… to see whether those topics were indeed as important as predicted.
		* Which is why we decided to focus on 2020-2021
			* We had wanted to analyse ten years, but the amount of time and labour needed to clean and cull a dataset that large was beyond the bounds of this project
		* UK
			* For now we are focusing on UK funders, but we would like to expand beyond that.
				* For 360Giving, it’s exclusively UK funders
				* For GtR it’s UK government research councils
				* For Lens, it is based on location of publication (???) 
					* (but this doesn’t appear to be accurate for every article. There are some that are not UK-based publications)
	* Downloaded the relevant datasets
	* Cleaned them
	* Culled them
	* Analysed them
	* The process and resulting datasets come with a number of caveats… 
		* Time intensive
		* Lens returned some results that didn’t appear to include any of our search terms(???)
		* Within Lens, filtering by ‘the UK’ meant the place of publication not researcher (???)
		* INSERT: anything else… 
		* Some articles in Lens are classed as journal articles because they come from a journal, but in reality they are book reviews, letters to the editor, reports on conferences, corrections, etc.
* We then moved to communicate the findings and the value of the process and infrastructure
	* Experimenting by presenting the findings in two different formats
	* The datasets are available online (can/ do we want to publish the datasets?)
