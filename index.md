# WIP Research Report for Dr Land

## This document contains an outline of a research report for the landscape review of data-related research (Dr Land). It follows a fairly standard structure. It will be shared on the ODI drive and sent to specific stakeholders, but it will not be published on the ODI website

**For the latest on the research questions yet to answer, see:  ** [Dr Land - Research questions - Phase 2](https://docs.google.com/document/d/1jvh6TVVehug1ZxbGLhV7iIeEXv66xHYp4ZEI1Bw5f98/edit#) 


 [Exec summary / abstract](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.7uf5j4ljkls3) 
 [Intro / What is the point/ value of this research?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.d75tg73bli4a) 
 [Approach/ methodology and overview of research question(s)](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.8o14535ellda) 
 [Findings/ results](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.o1vskbbf8yy4) 
 [Findings from qualt interviews with funders](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.j1an8etgjc5f) 
 [Recognition of “data-related research” as a field](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.nodxlqqgek0f) 
 [Recognition that the field is fragmented and the reasons why that is challenging](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.1w5m2wnh1rm9) 
 [Criteria to decide what to fund - agenda setters / followers](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.eppwu160v81m) 
 [Degree of collaboration and visibility of other funders in the field](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.1zbmb6ev6pk) 
 [Data-related research in the foreseeable future](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.eqq36j7xzefz) 
 [Supporting/ challenging our qualt findings with quant evidence](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.cyj2zya4x9h4) 
 [Analysis of ESRC funding over ten years](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.k1hah1w5m7za) 
 [Analysis of IUK funding over ten years](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.mjt1c8ky7txy) 
 [Discussion of these findings and any necessary caveats, clarification or context](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.27jat124xoar) 
 [Findings from our quant work](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.dtw8m1tp5m2s) 
 [Who is funding ‘data-related research’ (as a whole)](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.2gt7hajqf88d) 
 [Total amount of money for grants in 360Giving](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.5bsfebc30tqg) 
 [Total number of grants in 360Giving](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.kju9891dhy5j) 
 [Total amount of money for projects in GtR](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.8app36fv7vpc) 
 [Total number of discrete projects in GtR](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.x75jxrm7pfgk) 
 [Total number of publications funded by various funders within our Lens dataset](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.bh43ld9t22ao) 
 [Total number of citations of publications funded by various funders within our Lens dataset](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.fhjmn9uqpqp8) 
 [Discussion of these findings and any necessary caveats, clarification or context](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.z8nv5uvfvku7) 
 [How much funding is being directed at each of the ten keywords from ‘Data 2020’?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.qlr0uzeqxdml) 
 [Total amount of funding for each keyword in 360Giving (from 2012-2021)](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.1u72ws3jj9ux) 
 [Total amount of funding for each keyword in Gateway to Research (from YEAR-YEAR)](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.ky37a09pjuxv) 
 [Total amount of funding for each keyword in Lens Scholar (from YEAR-YEAR)](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.3yv3yub3a1y0) 
 [Discussion of these findings and any necessary caveats, clarification or context](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.wmlnngpbn8cv) 
 [Who is conducting ‘data-related research’?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.z7rz4jkvzuux) 
 [Who are the top 10 individual researchers conducting research in this area as a whole?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.ptyetq3umn0c) 
 [Who are the top (3?) individual researchers conducting research related to each of our ten keywords?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.6no3n4xb32rm) 
 [Who are the top 10 research organisations conducting research in this area as a whole?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.pr0uhojdmjwo) 
 [Who are the top (3?) researcher organisations conducting research related to each of our ten keywords?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.8e4tuzwszkxn) 
 [Discussion of these findings and any necessary caveats, clarification or context](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.1zcovp4j3c4p) 
 [Where is this research published, communicated and discussed?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.5ua9p8f3x4ek) 
 [Where are the top 10 places for publishing ‘data-related research’ as a whole?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.gkgyjxsay7rc) 
 [Where are the top (3?) places for publishing research related to each of our ten keywords?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.yjv4mcgzea9l) 
 [Discussion of these findings and any necessary caveats, clarification or context](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.euxmp31b6a2m) 
 [What are the top publications by citation for each keyword (from 2020-2022)?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.dwjehugltzqp) 
 [INSERT: links to Airtable views containing the top ~20 articles for each keyword based on number of citations](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.o79r74om1yqe) 
 [Discussion and future work](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.e8kbsur574xp) 
 [Trends we’ve identified in data-related research/ interesting points](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.7my4hp6jhz0g) 
 [QUESTIONS TO ANSWER: How many different ‘fields of study’ and areas of research is ‘data-related’ research spread across?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.hxnnxwbfqxi8) 
 [Potential uses for different audiences](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.15b6hsrwjjrm) 
 [Gaps and how to fill them](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.blvnn15q4i9q) 
 [Ideas for further work (basically an internal/external sales pitch for funding to continue work on this area)](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.y37hbypqpiaj) 
 [Sketching the short summary report](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.l7tx2z7ytxw) 
 [NB: What are we aiming to achieve with the piece?](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.psdzw4j4c3yz) 
 [Basic format](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.wc6df12ik280) 
 [Initial outline](https://docs.google.com/document/d/16NY5Xus-yJPr9RXCXSx2Y4BxidsRoGygUm_EILzR3f4/edit#heading=h.nskc1f747sxr) 




# Exec summary / abstract

* DO LAST:
	* Basic abstract
		* The overall purpose of the ~~study~~ (preliminary investigation) and the research problem(s) investigated; 
		* The basic design of the study; 
		* Major findings or trends found as a result of the analysis;
		* A brief summary of interpretations and conclusions.
	* People who will find it useful are… 
	* This research report was written by… 
# Intro / What is the point/ value of this research?

**Outlining the challenge and approach (borrowed from intro to short summary report)**
* Data is important and is having an impact (seemingly) everywhere.
* Because of this, research about data, its value, management, uses and impacts - what we call ‘data-related research’ - is being conducted nearly everywhere, sometimes in places you wouldn’t expect. 
	* Inside and outside academia (private and public sector, third sector, media, consultancy, industry - ie grey literature)
	* ‘Pure and applied’ 
	* Newer fields built explicitly around data like ‘critical data studies’ and older, more established fields like agriculture and [art?]
* And yet, despite the widespread importance of data in so many diverse parts of life] - or perhaps because of its widespread importance - it is extremely difficult to have a comprehensive view of all the research, writing and communication about data out there. 
	* Since data is everywhere, research about data is everywhere. 
* The fragmented and dispersed nature of this research field makes it difficult… 
	* … for researchers to identify relevant results in adjacent areas of enquiry, build on previous work, collaborate on shared interests, or coordinate to avoid duplicated effort. 
	* … for the audience and users of this research to locate and recognise research findings, insights and evidence that are relevant to their circumstances and needs. This can lead to [silos and people re-inventing techniques which were used in other domains - but don’t know how to even find this]
	* … for funders of data-related research and for those working to encourage research in this area to [coordinate, have visibility, spot peaks and troughs, etc.]
* To help provide visibility of this field of research, trace developments and link funding, research and impact, we conducted a [9 month?] mixed-methods research project… 	* We drew on methodologies such as landscape reviews, ‘research on research’, scientometric analysis, bibliometric analysis which have demonstrated their value in other fields of investigation and research such as funding for AI and cancer research… 
		* [If useful, could cite from]
			*  [https://www.diigo.com/item/pdf/8cpku/je07](https://www.diigo.com/item/pdf/8cpku/je07) 
			*  [https://diigo.com/0nr6ek](https://diigo.com/0nr6ek)  
			*  [https://diigo.com/0nr6fr](https://diigo.com/0nr6fr)  
			*  [https://diigo.com/0nr6hq](https://diigo.com/0nr6hq)  
	* The methodologies can even be used to examine the link between funding, research and impact in the past - which can help to understand the present and think strategically about the future
* [If useful, could cite from]
	*  [https://diigo.com/0nr6jg](https://diigo.com/0nr6jg)  
* We believe this research will be useful for a range of audiences
	* For funders
		* … more targeted in their funding, not be behind the curve, know what topics are hot right now, 
	* For researchers… 
		* [xxx]
	* For those who use research results…
		* [xxx]
* [Brief outline of the structure of the rest of the report…]

# Approach/ methodology and overview of research question(s)

* We worked from the ground up - letting the field emerge from the analysis rather than pre-defining the boundaries of the field
	* *Borrow as much as possible from the launch blog post and work note, eg why we’re not trying to define the boundaries of the field (ie working from the ground up) and starting with funders (ie tracing the funding cycle)*
* Our research questions were…
	* Our main research question was: What is going on in the data-related research landscape?
	* Our secondary research questions were:
		* Who is funding research in this area?
			* In the UK, who are the major funders of ‘data-related research’ - ie research about data, its value, uses and impacts?
			* How much funding do they direct toward ‘data-related research’ each year? How much in past years? How much is planned for future years?
			* What is the process for securing funding/ what are the requirements? 
		* What ‘data-related’ topics are being funded by these organisations? 
			* What is currently big in the world of data, tech, policy, governance, new uses of data, etc.? 
			* What are going to be the next big things in data over the next one, five, ten years?
	* Some of which could be answered via qualt research, some via quant, and some through a mix
* We started by speaking to funders because
	* It made sense to follow the money (funding → research → publication → impact)
	* It was more manageable
	* We spoke to 
		* Philanthropic funders
			* Wellcome
			* Sloan Foundation
			* Open Society
			* Ford Foundation
			* Lloyd’s Register Foundation
			* Nuffield Foundation
		* UK Research and Innovation (UKRI)
			* Biotechnology and Biological Sciences Research Council (BBSRC) 
			* Engineering and Physical Sciences Research Council (EPSRC)
			*   Arts and Humanities Research Council (AHRC)
			* Science and Technology Facilities Council (STFC)
			* Medical Research Council (MRC)
			* Natural Environment Research Council (NERC)
			* Innovate UK
	* Brief description of methods (but not too much - people understand interviews and thematic coding of transcripts)
		* Desk research on funders
			* Interested in understanding (a) general information about the organisation – core goals or mission, governance paradigm, and sector, (b) type of funding organisation – the functions it fulfils or services it provides, (c) main activities and projects going on.
		* Interviews with funders
			* Type of funders [research councils, philanthropic bodies, all doing research in the UK, interested in data-related topics] 
			* We asked them about
				* The role they see for themselves in the data-related research landscape
				* How they decide which topics to fund
				* How the application review process works
				* If/how they track the impact they have
				* If/how they engage with other funders as part of the funding process
* We then moved to quantitatively analyse funding, research, publication, impact
	* We first identified datasets that would enable us to answer our research questions, each of which has specific benefits and limitations
		* GtR
		* 360Giving
		* Lens Scholar (mention and thank Lens - probably also mention Lens near each table or chart)
	* Defined our parameters
		* Ten keywords chosen from Data 2020
			* For the sake of simplicity, we adopted an initial, heuristic definition of ‘data-related research’ as a cluster of ten keywords drawn from the ten ‘hot topics’ in  [Data 2020](https://theodi.org/article/data-2020/) .
				* Data ethics
				* Data sharing
				* Misinformation
				* Data infrastructure
				* Digital economy
				* Value of data
				* Data rights
				* Data literacy
				* Digital trade
				* Automated decision-making
			* Had to start somewhere in terms of what we meant by ‘data-related research’
				* With the intention of then expanding and snowballing these terms into adjacent terms, related areas etc.
			* This was the ODI’s estimation of what would be important in 2020, so this also enabled us to check our work in a sense… to see whether those topics were indeed as important as predicted.
		* Which is why we decided to focus on 2020-2021
			* We had wanted to analyse ten years, but the amount of time and labour needed to clean and cull a dataset that large was beyond the bounds of this project
		* UK
			* For now we are focusing on UK funders, but we would like to expand beyond that.
				* For 360Giving, it’s exclusively UK funders
				* For GtR it’s UK government research councils
				* For Lens, it is based on location of publication (???) 
					* (but this doesn’t appear to be accurate for every article. There are some that are not UK-based publications)
	* Downloaded the relevant datasets
	* Cleaned them
	* Culled them
	* Analysed them
	* The process and resulting datasets come with a number of caveats… 
		* Time intensive
		* Lens returned some results that didn’t appear to include any of our search terms(???)
		* Within Lens, filtering by ‘the UK’ meant the place of publication not researcher (???)
		* INSERT: anything else… 
		* Some articles in Lens are classed as journal articles because they come from a journal, but in reality they are book reviews, letters to the editor, reports on conferences, corrections, etc.
* We then moved to communicate the findings and the value of the process and infrastructure
	* Experimenting by presenting the findings in two different formats
	* The datasets are available online (can/ do we want to publish the datasets?)

# Findings/ results

# Findings from qualt interviews with funders

**See Sara’s  ** [doc with initial findings](https://docs.google.com/document/d/1jT3E3NUNoNhf1S0WpRz1G9ZgwKwdcJ-hOSHJpKeeqxA/edit#) 
**Recap (now with quant findings)**
* [Short intro to our qualt research…]
	* Recap of the questions we set out to answer 
* Yes, there appears to be an emerging field of research and shared interest here
	* Quant assessment:
		* Increase in funding and outputs related to data?
		* But can we find someone else talking about something similar?
* It is fragmented (and why is that bad)
	* Add any more findings related to how fragmented it is?
		* Quant assessment:
			* Number of different fields of study returned in our datasets?
			* Number of different journals and academic departments?
			* What’s missing? Almost everything outside of private sector, third sector, government research… 
				* Point to important publications from those orgs and show that they aren’t reflected in our dataset
			* ~~Number of universities?~~
* Funders do communicate (and collaborate sometimes) and are aware of other funding schemes, but much of this is maintained through informal contacts, relationships
	* Quant assessment:
		* Assessing degree of collaborations
			* Number of projects that are co-funded
			* Number of other orgs included as collaborators - and where they are from? Who is missing
* Some funders see themselves as setting the agenda, others do not.
	* Research councils primarily distribute funds. 
	* Philanthropics with a social component baked in are much more willing, generally speaking, to strive to steer the agenda
		* Quant backing: Was there any funder that made a claim about what they used to fund or what they plan to fund - eg 
			* ‘We want to do more about data justice’
			* One of the research councils talking about a past funding peak, focus… 

## Recognition of “data-related research” as a field
From the interviews, there seems to be general agreement that there is an emerging but fragmented field of research around data and its impact. There seems to be no specific definition of the field, as none of the participants have given one. Generally speaking, the field seems to be understood as emerging and often under-funded; for instance, someone from the Lloyd's Register Foundation said that “that type of space is historically a very underfunded community [and] . . . we fund mostly engineering”. Additionally, the details characterising each answer have differed from interview to interview depending on the role of the person interviewed. Indeed, people with a more technical background have defined the field around concepts such as data availability: “...essentially, we're creating whole new fields of quantitative data research that did not exist before, because the data just wasn't there” (participant X, ESRC - ADR UK Investment). On the contrary, people with a more social-sciences-based understanding spoke about the field in terms of accessibility, justice, and participation. Someone from Ford Foundation, for instance, said that “... lots of our work relevant to data has been about ensuring that values like justice, equity, accountability, transparency, consent, autonomy, and generally speaking, just that, that most needs and preferences of most impacted populations are being centred in the way we think about data” (participant X, Ford Foundation). Finally, again, although people agree that “a field that does research *about* data” exists, there seems to be a high degree of fragmentation and it is still rather hard to define it clearly.


## Recognition that the field is fragmented and the reasons why that is challenging
[xxx]

## Criteria to decide what to fund - agenda setters / followers
From the interviews, it seems that the criteria to decide what to fund are more about the quality of applications (‘we fund what is of high quality’) than they are about the topics investigated. Possibly because of the fragmentation of the field, indeed, it seems that funders are happy with any research being broadly related to their area(s) of research, and specifically focus on the feasibility and quality of the application. As one participant noted, “...all of [the] proposals will be batched in the same way, and then there will be assessment criteria based on quality” (participant X, Innovate UK). 
Moreover, based on interviews, the process of deciding what to fund in terms of topics to focus on seems to be a rather informal one, with input coming from both internal and external stimuli in a non-structured manner. 
Finally, it is worth noting how a lot of the organisations and funders we have spoken to seem to be both “agenda setters” and “agenda followers”; however, it is important to make a distinction between those whose agenda is set by an overall purpose (e.g. social justice, as in the case of Ford Foundation) or if that is broadly dictated by the overarching goal of funding research (as in the case of the research councils). For future research, it may be interesting to possibly dig deeper into the relationship between public/private funding and agenda setting processes.
## Degree of collaboration and visibility of other funders in the field
Broadly speaking, there seems to be visibility of others’ work in the field and a good degree of collaboration and exchange between funders. “I probably have at least one conversation during the week where I speak with a peer at another organisation” (participant X, McGovern Foundation). However, this seems to be mainly through personal connections developed through years of working in the field. Possibly, the process relies too much on individuals and its being rather informal makes it hard for new entrants to the system due to lack of formal network and tacit knowledge of the space. Indeed, as noted by someone with a rather relevant experience in the field, “...I've been in philanthropy for a while now . . . I feel we have a fairly strong network in philanthropy and in the data space, specifically” (participant X, McGovern Foundation). The personal / individual / informal nature of these processes also seems to be potentially challenging in terms of the transparency of the process as well as with respect to the space left for potentially unexplored territories as a result of an established network that acts as a filter bubble.
## Data-related research in the foreseeable future
The future of data-related research seems to be tied to the question of whether or not funders have a specific purpose that goes beyond funding research. Indeed, seeing the funding process as the means to a goal rather than the goal itself seems to lead to a difference in approach in terms of intentionally setting the research agenda and looking to the future with that specific perspective. For instance, someone mentioned how they *hope* to see topics such as data justice more at the centre of the data-related research agenda, and how their organisations seem to be heading that way: “I hope that it becomes second nature to think about power in conjunction with data . . . I am really thinking and hoping that we are going to see a shift there that like, you know, we're not going to keep talking about data driven technology without talking about how power is being distributed and or, or redistributed” (participant X, Ford Foundation). 
The choices about what to fund next are thus guided by an overarching, thematic, internal objective rather than by external influences. Moreover, those with no specific objective beyond funding and contributing research seem to have a harder time defining the future of the data-related research landscape; as one participant noted in an interview, breadth of topics is what really matters: “...it's more about getting that breadth of sort of topic of research area covered” (participant X, ESRC - ADR UK Investment). 

# Supporting/ challenging our qualt findings with quant evidence

* In order to compare our qualt and quant findings, we analysed the funding portfolios of two of the funders we spoke to over the last [10?] years
	* We chose to examine two government funders ESRC and Innovate UK
		* Below we outline the questions we asked and the findings we uncovered… 
			* Has their funding for data-related research increased over those ten years? 
				* In total amount? 
				* Total number of projects
				* As a percentage of that funder’s total funding budget? 
				* Has their funding for a specific data-related topic increased or decreased?
			* Who were the main recipients of their funding - ie research orgs and/or individual researchers?
				* In total amount? 
				* Total number of projects
				* As a percentage of that funder’s total funding budget? 
			* ~~Where is this research being published (probably not that interesting)~~
			* What has been the impact of that research?
				* How many citations? 
				* Has this gone up overall? 
				* Has this gone up within an individual keyword topic?
			* Do the quantitative findings support or contradict anything said during the interview with that funder
## Analysis of ESRC funding over ten years
* [xxx INSERT: table/chart xxx]
## Analysis of IUK funding over ten years
* [xxx INSERT: table/chart xxx]
### Discussion of these findings and any necessary caveats, clarification or context
* [xxx]

[INSERT: short outro to quant section]

# Findings from our quant work

**See    for the full set of questions/ findings** [Dr Land - Research questions - Phase 2](https://docs.google.com/document/d/1jvh6TVVehug1ZxbGLhV7iIeEXv66xHYp4ZEI1Bw5f98/edit#) 
* Short intro to our quant research…
	* Recap of the questions we set out to answer
## Who is funding ‘data-related research’ (as a whole)
* For this question we chose to focus on the top 10-20 funders based on a series of different metrics
	* Parameters
		* What: data-related research - ie the ten keywords
		* When: 2020-2021/22
		* Where: UK
	* Metrics
		* Total amount of money;
		* number of grants/ projects; 
		* total number of publications funded
	* Caveats, clarifications and context
		* The different databases don’t contain the same data/ columns
			* 360Giving doesn’t have publications
			* Funding data is harder to analyse within Lens for a given country
			* Project-level data for funders is spotty
### Total amount of money for grants in 360Giving / Total number of grants in 360Giving
**Funding Organisation**
Total amount (£)
Number of grants
**The Wellcome Trust**
£18,040,829.00
40
**Department for Business, Energy and Industrial Strategy**
£7,435,773.04
14
**Cabinet Office**
£2,409,375.00
1
**Esmée Fairbairn Foundation**
£650,000.00
2
**Department for Digital, Culture, Media and Sport**
£550,000.00
1
**Nuffield Foundation**
£339,157.00
1
**Joseph Rowntree Charitable Trust**
£178,350.00
2
**Indigo Trust**
£51,926.00
2
**Joseph Rowntree Reform Trust**
£32,084.00
1
**Barrow Cadbury Trust**
£29,000.00
1
**Department for Culture, Media and Sport**
£22,060.00
3
**Paul Hamlyn Foundation**
£10,320.00
1
**The National Lottery Community Fund**
£10,000.00
1
**Coop Foundation**
£7,941.20
1
**Foundation Scotland**
£3,470.00
1
**Grand Total**
**£29,770,285.24**
**72**

Within the 360Giving data set, there is approximately £30 million of funding for data related research across 72 grants.
### Number of projects and amount of money per funder in GtR
*FundingOrgName*
SUM of AwardPounds
COUNTA of ProjectId
Innovate UK
£29,162,355
24
EPSRC
£27,778,192
23
ESRC
£14,790,918
12
MRC
£9,211,246
8
UKRI
£2,007,222
3
NERC
£1,880,022
1
AHRC
£1,093,196
5
BBSRC
£332,068
2
**Grand Total**
**£86,255,219**
**78**

### Of the list of top UK funders, who are most occurring funders and what number of citations within our Lens dataset?
* Filter by citations
* Work down until we’ve identified 10 distinct funders
* Standardise the names if there are any variations
* Tally up the number of citations for each of those funders within the top 100
* (recognising it is an extremely small sample)
* (citations is a way of gauging impact, therefore, this is, in a way, top funder by impact)
* [xxx INSERT: table/chart xxx]

### Discussion of these findings and any necessary caveats, clarification or context
* [xxx]

## How much funding is being directed at each of the ten keywords from ‘Data 2020’?
* For this question we chose to focus not on individual funders, but on the total amount of funding (and projects?) for each of the ten keywords/topics that make up our initial sketch of ‘data-related research’
	* As discussed in the methods section, for the sake of simplicity, we are defining ‘data-related research’ as a cluster of ten keywords drawn from the ten ‘hot topics’ in  [Data 2020](https://theodi.org/article/data-2020/) .
		* Data ethics
		* Data sharing
		* Misinformation
		* Data infrastructure
		* Digital economy
		* Value of data
		* Data rights
		* Data literacy
		* Digital trade
		* Automated decision making
### Total amount of funding for each keyword in 360Giving (from 2012-2021)
* For 360Giving we are looking at grants awarded in the **ten years from 2012-2021** (ie since the founding of the ODI)
**Keyword**
SUM of Amount Awarded
COUNTA of Identifier
**Data sharing**
£22,381,082.10
48
**Digital economy**
£5,096,545.94
9
**Value of data**
£1,215,757.00
3
**Misinformation**
£588,360.20
5
**Data literacy**
£407,199.00
5
**Data ethics**
£49,257.00
1
**Data rights**
£32,084.00
1
**Grand Total**
**£29,770,285.24**
**72**

### Total amount of funding for each keyword in Gateway to Research (from YEAR-YEAR)
* (For GtR we are looking projects that started in the last two years, 2020-2022)
* **Important caveat**: including the keyword “misinformation” ballooned the returned results from the low hundreds up to 40,000 for reasons we could not understand. So we left it out. 

**Keyword**
**Amount of funding**
**Number of projects**
Digital economy
£48,855,033
19
Data sharing
£21,508,377
26
Data infrastructure
£17,795,271
18
Data ethics
£523,959
2
Automated decision making
£450,478
3
Data rights
£224,429
1
Value of data
£131,565
2
Digital trade
£0
1
Data literacy
£0
0

### Total citations for each keyword in Lens (from YEAR-YEAR)

**Keyword**
**Total citations**
**Number of publications**
Data sharing
1928
336
Misinformation
1088
136
Digital economy
659
75
Data infrastructure
283
44
Value of data
344
41
Automated decision making
118
19
Data ethics
325
16
Data literacy
261
12
Data rights
13
4
Digital trade
1
2



### Discussion of these findings and any necessary caveats, clarification or context
* [xxx]

## Who is conducting ‘data-related research’?

### Who are the top 10 ~research organisations~ conducting research in this area as a whole?
* For this question we are looking at data-related research as a whole - rather than at individual keywords - based on different metrics.
	* Who are the top 10 research organisations in this area by total amount of funding received? 
	* Who are the top research organisations in this area based on the total number of projects won? 

* ### 360Giving
*Recipient Org:Name*
SUM of Amount Awarded
COUNTA of Recipient Org:Name
COUNTUNIQUE of Award Year
MIN of Award Year
MAX of Award Year
UNIVERSITY OF OXFORD
£6,513,878.32
10
6
2014
2019
European Bioinformatics Institute
£2,815,112.00
2
2
2016
2020
King's College London
£2,712,590.00
2
2
2012
2014
GREATER LONDON AUTHORITY
£2,409,375.00
1
1
2019
2019
Newcastle University
£1,816,934.62
2
2
2015
2018
University of Warwick
£1,285,791.00
2
2
2012
2019
University of Dundee
£1,282,716.00
1
1
2020
2020
University of Liverpool
£1,192,228.00
1
1
2019
2019
EMBL - European Bioinformatics Institute
£1,000,000.00
1
1
2019
2019
London School of Hygiene & Tropical Medicine
£970,813.00
1
1
2013
2013

* ### Gateway to Research projects
	* Top 20 in order of amount funded
	* Caveat: not all projects have an amount of funding

*LeadROName*
SUM of AwardPounds
COUNTA of ProjectId
University of Edinburgh
£33,184,917
7
City, University of London
£7,178,672
2
University of Bristol
£6,972,599
2
University of Nottingham
£4,075,505
2
Lancaster University
£3,827,382
2
University of Surrey
£3,816,713
1
Newcastle University
£3,797,252
1
The Alan Turing Institute
£3,166,200
1
The Scottish Government
£2,117,000
1
University of Dundee
£2,032,574
1
University of Leeds
£1,959,639
2
Produce Logistics (UK) Limited
£1,418,633
1
Northern Ireland Stat Res Agency NISRA
£1,329,836
1
Queen's University of Belfast
£1,147,772
1
Sweetbridge Emea Ltd
£1,005,262
1
University of Cambridge
£768,683
1
LNRS Data Services Ltd
£737,964
1
University of Bradford
£687,857
1
Cranfield University
£550,218
1
University of Sheffield
£458,454
1


### Discussion of these findings and any necessary caveats, clarification or context
* [xxx]
* Producing a table of top authors by number of publications or citations would have been possible - either as a whole or for each keyword - but we decided not to because of reasons… 

## Where is this research published, communicated and discussed?
### Where are the top 10 places for publishing ‘data-related research’ as a whole?
* This will be based on our Lens dataset.
	* Are these primarily academic, public, private, third sector? Are they published openly or behind a paywall? Are they primarily peer-reviewed? Are results primarily written or are they communicated in other forms?
	* From Lens, Top “Source title” (journal title) by total count, include publication type, and include column on publisher
		* Behind the scenes: tally of country of publication (based on the Lens data - don’t actually go track it down)
* [xxx INSERT: table/chart xxx]

*Source Title*
COUNTA of Title
SUM of Citing Works Count
[No data]
48
519
Social Science Research Network
22
3
SSRN Electronic Journal
14
53
BMJ open
13
28
Journal of medical Internet research
12
385
PloS one
9
49
Wellcome Open Research
6
12
BMJ (Clinical research ed.)
5
72
IEEE Transactions on Engineering Management
4
9
IEEE Access
4
9
Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
4
1

*Publisher*
COUNTA of Title
SUM of Citing Works Count

77
384
Elsevier BV
53
306
Springer International Publishing
28
40
Cold Spring Harbor Laboratory
25
195
BioMed Central
25
353
BMJ Publishing Group
23
61
Institute of Electrical and Electronics Engineers (IEEE)
22
159
ACM
22
52
Springer Science and Business Media LLC
19
401
Oxford University Press
17
77
IEEE
16
79

### Where are the top (3?) places for publishing research related to each of our ten keywords?
* This will be based on our Lens dataset.
* Are these primarily academic, public, private, third sector? Are they published openly or behind a paywall? Are they primarily peer-reviewed? Are results primarily written or are they communicated in other forms?
* [xxx INSERT: table/chart xxx]

### Discussion of these findings and any necessary caveats, clarification or context
* [xxx]


## What are the top articles for data-related-research in Lens (from 2020-2022)?
### INSERT: Top (10-15) articles within Lens based on amount citation count (across all of data-related research)
* [insert table from Lens]

### INSERT: links to ten different Airtable views, each containing the articles in our Lens dataset that match a given keyword
* Basically a reading list of the most-cited academic articles for each keyword over the past two years (ie one view for data ethics articles, another for data justice articles) with results ranked by number of citations
	* TO CHECK: can we embed an airtable into Livemark? Each reading list could have its own page



# Discussion and future work

# Trends we've identified in data-related research/ interesting points

* Anything surprising or that confirms our suspicions? 
* The pandemic’s impact on funding
* Are we able to gauge the Data 2020 predictions?
* Is this an us (ie ODI) problem?
	* Are we the only ones who are looking for visibility across all these areas?
	* Yes, across the wide breadth, but there seem to be overlaps between some of the keywords, topics, themes etc, and those are likely to be interesting to other orgs/people, eg
		* Data ethics, data literacy, data governance
		* AI for good, autonomous decision making, AI ethics, explainability

### QUESTIONS TO ANSWER: How many different ‘fields of study’ and areas of research is ‘data-related’ research spread across?
* **ONE**: Using the ‘fields of study’ in the Lens dataset, is it possible to produce a list of all the fields of study in our culled dataset, ranked by the number of times that the field of study appeared in our dataset? **DONE**
	* This should help us expand our list of ten ‘data-related’ keywords (which were admittedly chosen semi at random based on the contents of Data 2020) to a larger set of 20-30 fields of study that can be used to define the WIP boundaries of data-related research.
	* It should also help us replace any of the ten keywords that may have a better, more standardised field of study that we should be searching for.
		* For instance, ‘data rights’ does not appear as a field of study in our dataset, but ‘digital rights’ does. Possibly data rights is not an established field of study. Going forward, we could search for digital rights instead
	* We could then continue this process in the future by searching for other relevant keywords that seem to be missing from our list, download the related articles, cull them to ensure they are relevant, then add any new relevant fields of study to our growing list of standardised fields of study within the emerging field of ‘data-related research’
* **TWO**: Using the fields of study in the Lens dataset, is it possible to define the top 5-10 fields of study relevant to each of our ten keywords? eg for those articles tagged as ‘automated decision-making’, what are the top 5-10 fields of study?
	* This would be helpful to better target searches for topics that do not have clear keywords or search terms. For instance, ‘automated decision making’ is not a field of study in our dataset. Knowing the top five fields of study related to the articles we tagged as ‘automated decision making’ would potentially help people interested in automated decision-making to target their search to capture relevant articles.
* **THREE**: Using the ‘fields of study’ from the Lens dataset, is it possible to visualise the wide landscape of academic research (math(s), physics, chemistry, biology, social science, arts and humanities, etc) and then show the amount of ‘data-related research’ being conducted within each of those areas? 
	* Basically a cluster diagram similar to this one about meta-research (research on research) being conducted in different fields…
[image:9D85ED8A-0D9A-476D-B6DA-1A6B875B2118-73672-000000DBCA7EBD7D/xASAQqIyXVMgEPtgPWTTHTP9FZQY8ScWj5tKLDcI22oJsbmnrRrHY8Bz_nKVXcIXZaO9lvK8URASYByZM4iI-vbtriF_ndOSD-SbT2H5UgkDp5MJcGJABGGX5AW3TZCcDJFUJOyy.png]
Possibly using  [this free(?) tool](https://www.vosviewer.com/)  recommended to us by RORI
* Short of this, even a list of fields of study related to different areas of academic research would be useful - eg a list showing fields of study related to math(s), biology, computer science, social science, economics, arts and humanities, etc

# Potential uses for different audiences

* Researchers
* Funders
* Users of research
* Policymakers
* Research on research

# Gaps and how to fill them

* *Basically a repeat of the gap-related points from the short summary report (see section below)*

# Ideas for further work (basically an internal/external sales pitch for funding to continue work on this area)

* **Overall pitch**
* There is a problem here, and we don’t know the answer, but we are committed to following up, including through further research, collaborations and playing a role as a convener… 
* **Filling in the landscape outside of government-funded academic research**
	* In the short term, further work to track funding within academia across different funders, regions, types of funding for specific topics. 
		* Sites like 360Giving and Gateway to Research provide some of this functionality, but not a wide enough view. How could this be improved?
	* In the medium term, further work could focus on the non-academic world to confirm whether:
		* It is *~possible~* to fill some of these gaps, eg by going directly to non-academic research orgs to link funding, projects and outputs
			* What other orgs are trying to map grey literature? Are these services useful?
				* Overton
				* Dimensions includes some policy/government reports
				* Altmetrics tracks some relevant aspects
		* It is *~useful~* to fill these gaps to get a more holistic view of research about data - eg being able to trace research about data from funding to output for more than just academic orgs. Can academic and non-academic be combined in an easy/meaningful way?
		* It is *~difficult~* to fill these gaps, possibly because it is time consuming with fewer systems in place
		* (aka Dr Land 2.0 - The Squeakquel) 
	* In the long term, the ODI could explore how to convene different parties and stakeholders from inside/outside academic to work to fill in the gap around ‘grey literature’
		* Convene events and workshops with relevant stakeholders
			* Eg an event with the members which is partly about gauging whether they also see a challenge and what they think might be the solutions… 
		* Explore options for adopting and adapting standards used within academia to track research outside of academia
		* Explore options for tracking non-academic research beyond of the standard methods used within academia
		* To lead by example, the ODI could publish **its own** reports and outputs in a way that is aligned with or interoperable with existing academic systems, eg by:
			* Identifying whether workable systems, schemas and publishing standards exist to publish, catalogue and connect its own to academic research
			* Demonstrating the value of doing this
			* Working with other non-academic orgs to understand their views on the matter and possibly co-designing ways of moving forward, eg by pushing the adoption of publishing standards and/or cataloguing outputs from non-academic orgs to submit them to sites like Lens Scholar
* **Work to produce a semi-automated way of searching databases like Lens and OpenAlex**
	* Every article in Lens has a list of relevant keywords and fields of study. Since we hand-culled the datasets, they should be relevant. 
	* Meaning we now have a fairly expansive set of keywords and fields of study that can serve as a starting point to define the rough boundaries of ‘data-related research’. 
		* We also have lists of fields of study for each of our ten keywords
	* We should be able to repurpose those lists to help us - and others - to search for ‘data-related research more efficiently and effectively, eg
		* For someone interested in data ethics we might be able to point them to:
			* The top 10 keywords to include with their search in order to narrow down the results and reject unuseful articles
			* The top related academic disciplines/ fields of study
			* Areas of overlap with other concepts or keywords
			* The top journal articles to focus on
			* The top research organisations working in that field
* **Making our datasets and/or infrastructure available externally**
	* OPTIONAL: An ~~interactive dashboard~~ or simply a spreadsheet that interested parties can use to conduct their own research in this area 		* The data we use should be available to download 
			* Assuming the platforms share data with appropriate licenses (Lens might be quite restrictive?)
		* Visualisations should also be reusable
		* An airtable with some of our datasets that is open and viewable


# Sketching the short summary report

### NB: What are we aiming to achieve with the piece?
* How **does** this compare to the longer research report?
	* This short summary aims to put forward an argument, backed up by evidence at each stage, regardless of whether that is qualt evidence from interviews, quant evidence or desk research. It is meant to demonstrate the importance of the work and the challenge and convince people (internally/ externally) to collaborate with us to tackle this challenge… 
		* The longer research report, on the other hand, is roughly chronological and lays out the bulk of our findings as well as our methodology. In a way, it is annex where those who are interested to learn more can turn for further detail.
* **Primary aims**
* Make the case that there is a field of data-related research, with lots of overlapping interest, research activity, terminology, but ultimately fragmented
* Provide at least some visibility of the fragmented field of data-related research for funders, researchers and potential users of research findings
* Advertise the value of high level views of funding research, publications 
* Make a case for further work
* **Secondary aims**
* Communicate interesting findings from our work
* Advertise the value of this kind of quant research
	* (can be pushed internally, so not a primary goal within this short piece)
* Describe the infrastructure we've produced and advertise the value of it for the ODI (and possibly others) 
	* (can be pushed internally, so not a primary goal within this short piece)
### Basic format
* 10-15 slides with a few sentences on the left, paired with some form of evidence on the right - eg a quote, image, table or chart

# Initial outline


*NB: I find it difficult to work collaboratively in google Slides, so I’m recommending we work in google Docs as long as possible before transferring the short summary report over to a slide deck. To that end, I have arranged the short summary report as a table with 20 rows, with the rough draft of the text/prose on the left and initial ideas for evidence (tables, charts, graphs, images, quotes, etc) on the right. This can roughly approximate a slide with text on the left and some sort of visual on the right. I hope it will be easier to work collaboratively within this format than in google slides*

Slide 
#
Text/ prose
Evidence (eg a quote, image, table or chart)
1
**Section 1: [Introducing the value and challenge]**

Data is important and is having an impact (seemingly) everywhere. 
INSERT: Collage of headlines/titles from media articles and research reports alluding to the importance of data and its widespread impacts… 

OR: QUOTE from external report or article
2
Because of this, research about data, its value, management, uses and impacts - what we call 'data-related research' - is being conducted nearly everywhere, sometimes in places you wouldn't expect. 
* Inside and outside academia (private and public sector, third sector, media, consultancy, industry - ie grey literature) 
* 'Pure and applied' 
* Newer fields built explicitly around data like 'critical data studies' and older, more established fields like agriculture and [art?] 
INSERT: Collage of reports and articles from the wide range of places mentioned above. 
3
And yet, despite the widespread importance of data in so many diverse parts of life] - or perhaps because of its widespread importance - it is extremely difficult to have a comprehensive view of all the research, writing and communication about data out there. 

Since data is everywhere, research about data is everywhere. 

4
The fragmented and dispersed nature of this research field makes it difficult… 
* … for researchers to identify relevant results in adjacent areas of enquiry, build on previous work, collaborate on shared interests, or coordinate to avoid duplicated effort. 
* … for the audience and users of this research to locate and recognise research findings, insights and evidence that are relevant to their circumstances and needs. This can lead to [silos and people re-inventing techniques which were used in other domains - but don't know how to even find this]
* … for funders of data-related research and for those working to encourage research in this area to [coordinate, have visibility, spot peaks and troughs, etc.]

5
In 2021 we conducted research aimed at identifying whether it is possible to produce a high-level overview of research related to data, its value, management, uses and impacts. 

Our broader aims were to catalogue research, knowledge and thought related to data, and proactively identify emerging data-related topics worthy of investigation.

6
Though definitions differ, our research [found broad agreement] that there is indeed a burgeoning field of data-related research
INSERT EVIDENCE from interviews: Either, a nice quote from an interviewee or something like:
* “We spoke to ## people working to fund research about data in some shape or form within philanthropic and government organisations, and # agreed…”  
7
But while there seems to be agreement that a field of research is developing around data, it is fragmented and dispersed. Unlike other disciplines or areas of inquiry where it is easier to draw a boundary around relevant topics, results and methods of investigation, this is much more difficult [when attempting to gather research about data, its value, etc etc]

There are fields that cover parts of that landscape - eg data studies or [INSERT another] - but even these have overlaps with other fields and don't cover everything… 

The terminology also makes it difficult (different words for similar concepts. Not enough time for the field to coalesce around shared terminology.)
INSERT EVIDENCE from interviews: Either, a nice quote from an interviewee or something like:
* “We spoke to ## people working to fund research about data in some shape or form within philanthropic and government organisations, and # agreed…” 
AND/OR: back this up with quant evidence, eg:
* A search in Lens Scholar for ten keywords related to data and data-related research returned #### articles published from Jan 2020 (see the research report for details)…
* Those articles came from ### different [fields of research / university departments] ranging from [computer science and data studies to art, agriculture and philosophy, etc]
8
**Section 2: [Filling in some of the landscape]**

However, using some totes sweet quant methods it is possible to begin sketching the broad contours of the landscape of data-related research. 

We identified three [open/ free] databases that contained information on funding and research related to data and developed a list of 10 keywords that roughly approximate data-related research. 

The process is time and labour intensive, but by searching these databases for 10 keywords we were able to identify the main funders, research orgs, publications and departments /fields within the landscape of data-related research in the UK over the last two years. (For more on our findings, our methodology and the limitations of some of the databases we used, see the research report…) 
INSERT: logos of Lens, GtR and 360Giving?
OR: our ten keywords?
9
*Discussion of main funders…*
INSERT: tables, charts or graphs with a bit of explanation

(NB: This could involve choosing one database and one metric for a given question - eg the main research orgs, using Lens Scholar data, based on the number of publications…) 
10
*Discussion of main research orgs…*
INSERT: tables, charts or graphs with a bit of explanation

(NB: This could involve choosing one database and one metric for a given question - eg the main research orgs, using Lens Scholar data, based on the number of publications…) 
11
*Discussion of main journals…*
INSERT: tables, charts or graphs with a bit of explanation

(NB: This could involve choosing one database and one metric for a given question - eg the main research orgs, using Lens Scholar data, based on the number of publications…) 
12
*Discussion of main fields of study…*
INSERT: tables, charts or graphs with a bit of explanation

(NB: This could involve choosing one database and one metric for a given question - eg the main research orgs, using Lens Scholar data, based on the number of publications…) 
13
These results and this type of analysis can be useful for:
* Researchers looking for
	* Areas of major activity
	* Staying up to date on emerging ideas and topics
	* Overlapping interest/investigation and potential for mutual benefit
	* Lit reviews
	* Potential sources of funding
	* Identifying experts to collaborate with
* Users of research interested in
	* Relevant research in unexpected fields
	* Collaborators and experts
* Funders looking to
	* Identify peaks and troughs of funding across the field
	* Understand the funding focus of other funders
	* Stay up to date on emerging ideas and technologies worth funding

14
**Section 3: [Spotlighting gaps and outlining future work]**

However these results are based on an extremely small section of the entire landscape, in large part because there are major gaps in the evidence base. 

15
One gap is related to open v paid access

Many of the best systems for tracking research and funding exist behind paywalls. 
* Fully paid: Elsevier, Scopus, Web of Science
* Part-paid: Dimensions 

Many universities and research organisations of course pay for access to these, but for many people and smaller research orgs, these costs are prohibitive… 

16
Another major gap is related to funding info

There is not much info about funding within many of the services that exist to track funding and research - paid or free. (OPTIONAL INSERT: Paraphrase quote from openalex: it is difficult to get funding data from open sources…)

When you restrict your search to research with funding details within a site like Lens Scholar, it is a very small percentage. Of our corpus of ### data-related research articles from 2020-2021, only ## list their funding info 

The funding that is captured in services like Lens or 360Giving is largely government funding, but some philanthropics are good at publishing data. 

On the whole, many articles do not state their funding sources, and most other funders (private sector, third sector) don’t seem to publish details about their funding.

The current setup therefore misses funding from third sector research institutes, industry, consultancies, tech companies, the media etc, potentially leading to blind spots, silos duplication of effort.
OUTDATED INFO, but this indicates scale…
All scholarly works in Lens (search = *)
245,487,401
Search of our ten keywords 2012-2021 [~[LINK](https://www.lens.org/lens/search/scholar/list?q=(%22data%20ethics%22)%20OR%20(%22data%20sharing%22)%20OR%20%22misinformation%22%20OR%20(%22data%20infrastructure%22)%20OR%20(%22digital%20economy%22)%20OR%20(%22value%20of%20data%22)%20OR%20(%22data%20rights%22)%20OR%20(%22data%20literacy%22)%20OR%20(%22digital%20trade%22)%20OR%20(%22automated%20decision%20making%22)&p=0&n=10&s=_score&d=%2B&f=false&e=false&l=en&authorField=author&dateFilterField=publishedYear&orderBy=%2B_score&presentation=false&preview=false&stemmed=true&useAuthorId=false&publishedYear.from=2012&publishedYear.to=2021)~]: 
101,641
Filtered by ‘has funding’ info
20,158
Filtered by only UK funders
5,766
Filtered by ‘open access’
5,718
Filtered by ‘has abstract’
5,676
Filtered by has a funder project number
####
Table showing the proportion of ‘data-related’ research publications in our Lens Scholar dataset that have enough data attached to make it possible to track: funding org, funder project, recipient org, recipient researcher, outputs and impact

17
Another large gap is research outside of academia… Much research about data is ‘grey literature’ and does not appear to be captured in current systems for tracking funding, research, outputs, impact etc.

This is a problem because a lot of excellent thought leadership and advances in this field can and does happen outside of academia in research institutes, government, industry, consultancies, tech companies, the media etc and important conversations happen outside of academic journals - eg in non-academic conferences, the media, on social media.
INSERT: quote from article about the misconception of innovation flowing from academia out to society… 

OR: list of the major research orgs, consultancies, industry orgs etc that are not captured in current systems, as well as some of the major conferences, newspapers, etc
18
Two groups are talking about similar concepts without much collaboration. For instance, the ODI’s publications do not appear within these tracking and lit review systems (eg Lens) nor do they appear in academic publications. Similarly, academic publications do not feature in our lit reviews or in our publications. 

But many of the research projects and papers contained in our dataset would be relevant to the ODI. (Presumably the same would be true of the value of our research for academics.)
INSERT: a search of Lens or OpenAlex to see the extent to which orgs like the ODI, Ada, CDEI are cited in academic articles
AND: a search of ODI, Ada, CDEI literature to see how often academic articles are cited
19
Our work has demonstrated the value of mapping parts of the landscape of data-related research and of being able to track government-funded academic research. 

But there are gaps in the landscape that need to be filled - particularly around documenting and tracking non-government funding and non-academic research. 

Until these gaps are filled, funders, researchers and those who use research findings will struggle to develop [even a moderately comprehensive] view of the entire landscape of data-related research. 

20
We are committed to addressing these problems, including by working to convene interested people and organisations to understand the challenges better and co-develop strategise to address them. 

We welcome any and all help. 

Please let us know if you are interested in joining us. 




